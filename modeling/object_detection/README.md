# Car Detection System with ResNet50 Backbone

A simple and readable car object detection system using PyTorch and Faster R-CNN with ResNet50 backbone. This project fulfills the requirements for the PNU ISLAB technical AI test 2025.

## ğŸš— Project Overview

This project implements a car detection system that can:
- Detect multiple car instances in images
- Process single images, batch images, and videos
- Use ResNet50 as the backbone network through Faster R-CNN
- Provide clean, readable, and well-documented code

## ğŸ“ Project Structure

```
cv_task_pnu/
â”œâ”€â”€ modeling/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ training_images/          # Training images
â”‚   â”‚   â”œâ”€â”€ testing_images/           # Testing images
â”‚   â”‚   â”œâ”€â”€ train_solution_bounding_boxes.csv  # Annotations
â”‚   â”‚   â””â”€â”€ sample_submission.csv
â”‚   â””â”€â”€ object_detection/
â”œâ”€â”€ car_detection_training.py         # Training script
â”œâ”€â”€ car_detection_inference.py        # Inference script
â”œâ”€â”€ data_preparation.py               # Data analysis and preparation
â”œâ”€â”€ requirements.txt                  # Dependencies
â”œâ”€â”€ main.py                          # Main entry point
â””â”€â”€ README.md                        # This file
```

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Install dependencies
pip install -r requirements.txt

# For M-series Mac users, also install:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

### 2. Data Preparation

First, check your data structure and prepare the dataset:

```python
python data_preparation.py
```

This script will:
- âœ… Check if your data structure is correct
- ğŸ“Š Analyze your annotations
- ğŸ” Validate images and bounding boxes
- ğŸ“ˆ Generate visualizations
- ğŸ“‚ Create train/validation splits

### 3. Training the Model

```python
python car_detection_training.py
```

Training features:
- ğŸ—ï¸ **Architecture**: Faster R-CNN with ResNet50 backbone
- ğŸ¯ **Task**: Car object detection (binary: background vs car)
- ğŸ“Š **Monitoring**: Real-time loss tracking and visualization
- ğŸ’¾ **Checkpoints**: Automatic model saving every 2 epochs
- ğŸ“ˆ **Visualization**: Training loss plots and sample predictions

### 4. Running Inference

```python
python car_detection_inference.py
```

Inference capabilities:
- ğŸ–¼ï¸ **Single Image**: Detect cars in one image
- ğŸ“ **Batch Processing**: Process multiple images
- ğŸ¬ **Video Processing**: Real-time car detection in videos
- ğŸ“Š **Results**: Automatic visualization and saving

## ğŸ“‹ Data Format Requirements

Your annotations CSV should have these columns:
- `image_path`: Relative path to image
- `xmin`, `ymin`, `xmax`, `ymax`: Bounding box coordinates
- `class_name` (optional): For compatibility

Example:
```csv
image_path,xmin,ymin,xmax,ymax,class_name
car001.jpg,100,50,300,200,car
car001.jpg,350,100,500,250,car
car002.jpg,80,60,280,180,car
```

## ğŸ› ï¸ Model Architecture

```
Faster R-CNN with ResNet50 Backbone
â”œâ”€â”€ Backbone: ResNet50 (pre-trained on ImageNet)
â”œâ”€â”€ Feature Pyramid Network (FPN)
â”œâ”€â”€ Region Proposal Network (RPN)
â””â”€â”€ ROI Head with FastRCNN Predictor
    â”œâ”€â”€ Input Features: 1024
    â””â”€â”€ Output Classes: 2 (background + car)
```

## âš™ï¸ Configuration Options

### Training Configuration
```python
config = {
    'batch_size': 4,           # Adjust based on GPU memory
    'num_epochs': 10,          # Training epochs
    'learning_rate': 0.005,    # Learning rate
    'momentum': 0.9,           # SGD momentum
    'weight_decay': 0.0005,    # L2 regularization
    'num_classes': 2,          # background + car
}
```

### Inference Configuration
```python
confidence_threshold = 0.5     # Detection confidence threshold
device = 'cuda' or 'cpu'       # Automatic device selection
```

## ğŸ“Š Performance Monitoring

The training script automatically generates:

1. **Training Loss Plot** (`training_loss.png`)
   - Real-time loss tracking
   - Saved automatically after training

2. **Detection Visualizations** (`detection_results.png`)
   - Sample predictions with ground truth
   - Green boxes: Ground truth
   - Red boxes: Predictions

3. **Model Checkpoints**
   - `checkpoint_epoch_X.pth`: Intermediate checkpoints
   -